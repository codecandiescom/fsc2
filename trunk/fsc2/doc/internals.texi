@c $Id$
@c
@c Copyright (C) 1999-2003 Jens Thoms Toerring
@c
@c This file is part of fsc2.
@c
@c Fsc2 is free software; you can redistribute it and/or modify
@c it under the terms of the GNU General Public License as published by
@c the Free Software Foundation; either version 2, or (at your option)
@c any later version.
@c
@c Fsc2 is distributed in the hope that it will be useful,
@c but WITHOUT ANY WARRANTY; without even the implied warranty of
@c MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
@c GNU General Public License for more details.
@c
@c You should have received a copy of the GNU General Public License
@c along with fsc2; see the file COPYING.  If not, write to
@c the Free Software Foundation, 59 Temple Place - Suite 330,
@c Boston, MA 02111-1307, USA.


@node Internals, Modules, Cloning Devices, Top
@chapter Internals


In this chapter I will try to explain in some more detail how
@code{fsc2} works internally. I hope that this will help especially if
you're going try to write a new module for a device (or if you get upset
about things @code{fsc2} does differently from the way you would like it
to).


As you will already have understood, @code{fsc2} is basically an
interpreter for @code{EDL} scripts. Normal interpreters interpret each
line of input individually, i.e.@: analyze a line, and, if the line is
syntactically correct, execute it. That's what @code{fsc2} also does,
but only for the parts before the @code{EXPERIMENT} section. In
contrast, the interpretation of the @code{EXPERIMENT} section of an
@code{EDL} file consists of several steps. In the first step the
@code{EXPERIMENT} section as a whole is read in and only syntax checks
are done. In the second step a complete test run of @code{EXPERIMENT}
section of the script is done to avoid that the experiment will have to
be stopped due to obvious logical errors in the @code{EDL} script. The
device modules are involved, i.e.@: they already can do all kinds of
checks on what can be expected to happen during the real experiment and
detect possible problems.


Only if all these tests succeeded the third step, the execution of the
@code{EXPERIMENT} section of the @code{EDL} script, is started, i.e.@:
the experiment is run. When an experiment is restarted (without
reloading the @code{EDL} file) only this third step is repeated.


In the following what happens during the three steps of the execution
of an @code{EDL} script will be explained in some more details. Then
follows a real long section that tour de force through the sources of
the porgram. This is hopefully going to be helpful for people that try
eliminate bugs or even extend @code{fsc2}.



@ifinfo
@menu
* First stage of interpretation::
* Second stage of interpretation::
* Third stage of interpretation::
* Reading the sources::
@end menu
@end ifinfo


@node First stage of interpretation, Second stage of interpretation, Internals, Internals
@section First stage of interpretation


In the first stage of the interpretation the script is read in a token
by token fashion, where tokens are e.g.@: variable or function names,
numbers, braces, semicolons, section labels etc. This is mainly done by
the code within the files which you'll find in the @file{src} directory,
having an extension of @code{.l}. As you will see there's such a file
for each of the different sections an @code{EDL} script may
contain. Actually, there are some extra ones, @file{split_lexer.l} is
the central switch for the first stage that calls the individual
tokenizers in turn on finding a new section label and also deals with
error conditions that couldn't be handled by the section
interpreters. Two extra tokenizers, @file{devices_list_lexer.l} and
@file{func_list_lexer.l} are for analyzing the files with the list of
device modules, @file{conf/Devices}, and the list of functions,
@file{conf/Functions} (they also contain some additional @code{C} code
for interpreting the tokens).


Finally, there is @file{fsc2_clean.l}. @code{EDL} itself expects its
input to be a single file in a certain format. Thus it does not deal
directly with the input files (there can be more than one when there are
@code{#INCLUDE} statements in an @code{EDL} script). Therefore, there's
an extra program, @file{fsc2_clean} that translates the input @code{EDL}
script into a form that the main program understands. @code{fsc2_clean}
for example removes all comments, includes files for @code{#INCLUDE}
statements, adds information about line numbers and file names, deals
with physical units etc.@:, and then passes this cleaned-up input to
@code{fsc2}. If you are interested what @code{fsc2} really sees of an
@code{EDL} file you can run @code{fsc2_clean} with the @code{EDL} file
as its standard input, i.e.@:
@example
fsc2_clean < edl_script.edl
@end example
@noindent
(please note that the output of @code{fsc2_clean} program contains some
non-printable characters).


The lines of @code{EDL} script in the sections preceeding the
@code{EXPERIMENT} section are executed immediately. E.g.@: during the
handling of the @code{DEVICES} section the modules for the listed
devices are loaded and the functions defined in the modules are included
into @code{fsc2}s internal list of functions that can be used from
within the @code{EDL} script. While reading the @code{VARIABLES} section
the newly defined variables are added to @code{fsc2}s list of variables,
and, if necessary, initialized.


While the tokenizers (i.e.@: the files with an extension of @code{.l})
are used for splitting of the input into manageable tokens, the
execution of the code (now consisting of a stream of tokens) is done in
the files with an extension of @code{.y} (or, to be precise, by the code
generated from these files). In these files, the parsers, actions
(mostly a few lines of @code{C} code) are executed for syntactically
correct sets of tokens. Because actions can only be executed for input
with valid syntax, these files practically define what is syntactically
correct and what is not.


To give you an example, here's a very simple statement from an
@code{EDL} script:
@example
a = B_x + 3;
@end example
The tokenizer doesn't has too much to do in this case, it will output a
list of the tokens of this line, together with some information about the
class the individual tokens belong to. So, it will pass the following
kind of information to the parser:
@example
Floating point variable named 'a'
Equal operator
Integer variable named 'B_x'
Plus operator
Integer number with a value of 3
End of statement character: ;
@end example
@noindent
The parser, in turn, has a list of all syntactically correct
statements@footnote{Actually, the parser does not really has a list of
all syntactically correct statements but contains a set of rules that
define exactly how such statements may look like. One of these rules for
example is that a variable name and an equal operator may be followed by
either a variable, a function call or an integer or floating point
number. Anything not fitting this pattern is a syntax error.}, together
with the information what to do for these statements. One of the rules
is that a statement consisting of sequence of the tokens
@example
Variable, Equal operator, Variable, Plus operator,
integer number, end of statement character
@end example
@noindent
is syntactically correct and that for this sequence of tokens some
@code{C} code has to be executed that fetches the value of the variable
@code{B_x}, adds it to the integer number and finally stores the result
into the variable @code{a}. Statements that are not in the parsers list
are @i{per definitionem} syntactically incorrect. For example, there is
no rule on how to deal with a sequence of tokens as the one above but
with the integer number missing. Because the parser looks at the
statements token by token it won't complain while getting the first four
tokens up to and including the plus operator. Only if the end of
statement operator, the semicolon, is found directly after the plus sign
it will recognize that there is no rule on how to deal with the
situation, print the error message @code{Syntax error near token ';'}
(plus the file name and line number) and abort.


The @code{EXPERIMENT} section is handled differently. Most important,
the code of the @code{EXPERIMENT} section is not executed at this
stage. It is just split up into its tokens and only some rudimentary
syntax check is done, e.g.@: undefined variables or mismatched braces
etc.@: are detected. Instead, an internal list of all the tokens the
@code{EXPERIMENT} section consists of is created. This list is later
used to test and execute the @code{EXPERIMENT} section.


Writers of modules should know that the modules already get loaded when
the @code{DEVICES} section (which always must be the first section) is
dealt with. A module may contain a special function, called a hook
function, that automatically gets called when the module has just been
loaded.  This allows for example to set the internal variables of the
module to a well-defined state. This function may not call any functions
accessing the device because neither the GPIB bus nor the serials ports
(or any other devices like ISA or PCI cards) are configured at this
moment.


While handling the part of the @code{EDL} script up to the start of
the @code{EXPERIMENT} section, functions from the modules may be called
(unless they have been explicitely declared to be used only during the
experiment). Usually such function calls will be used to define the
state of the device at the start of the experiment. For example, the
@code{PREPARATIONS} section may contain a line like
@example
lockin_sensitivity( 100 uV );
@end example
@noindent
When @code{fsc2} interprets this line it will call the appropriate
function in the module for the lock-in amplifier with a floating point
number of @code{0.0001} as the argument (the module does not have to
take care of dealing with units, they are already translated by
@code{fsc2}, or, to be precise, by @code{fsc2_clean}).  The module
function for setting the lock-in amplifiers sensitivity should now check
the argument it got passed (there may or may not be a sensitivity
setting of @code{0.0001} and only the module knows about this). If the
argument is reasonable the module should store the value as to be set
when the lock-in amplifier finally gets initialized at the start of the
experiment.


How to deal with wrong arguments or arguments that don't fit (e.g.@: if
the argument is @code{40 uV} but the lock-in amplifier has only
sensitivity settings of @code{30 uV} and @code{100 uV}) is completely up
to the writer of the module, @code{fsc2} will accept whatever the module
returns. For example, the module may accept the argument after changing
it to something to the next possible sensitivity setting and printing
out a warning or it may bail out and tell @code{fsc2} to stop
interpreting the @code{EDL} script.


Another thing module writers should keep in mind is that this first (and
also the second) stage is only run once, while the experiment itself may
be run several times. Thus it is important that the values with which a
device must be initialized at the start of an experiment are stored in a
way that they aren't overwritten during the experiment. For example, it
does not suffice to have one single variable for the lock-in amplifiers
sensitivity because the sensitivity and thus the variable might get
changed during the experiment.


@node Second stage of interpretation, Third stage of interpretation, First stage of interpretation, Internals
@section Second stage of interpretation


The second stage of the interpretation of an @code{EDL} script is
the test run of the @code{EXPERIMENT} section. A test run is necessary
for two reasons. First, only a very rudimentary syntax check has been
done for the @code{EXPERIMENT} section until now. Second, and much more
important, the script may contain logical errors and it would be rather
annoying if these would only be found after the experiment had already
been run for several hours, necessitating the premature end of the
experiment. For example, without a "dry" run it could happen that only
after a long time it is detected that the field of the magnet is
requested to be set to a value that the magnet can't produce. In this
case there usually are only few alternatives, if any, to aborting the
experiment. Foreseeing and taking the appropriate measures for such
possibly fatal situation would complicate both the writing of modules
and @code{EDL} scripts enormously and probably would still not catch
all of them.


By doing a test run, on the other hand, for example the function for
setting the magnet to a new field will be called with all values that
are to be expected during the real experiment and thus invalid field
settings can be detected in advance. Doing a test run is much faster
than running the experiment itself because during the test run the
devices will not be accessed (which usually uses at least 90% of the
whole time), calls of the @code{wait()} function do not make the program
sleep for the requested time, no graphics are drawn etc.


The writers of modules have an important responsibility to make running
the test run possible. During the test run the devices can't be
accessed. Despite this the modules have to deal in a reasonable way with
requests for returning data from the devices. Thus the modules must,
during the test run, "invent" data for the real ones. This can be a bit
tricky and special care must be taken to insure that these "invented"
data are consistent. For example, if a module for a lock-in amplifier
first gets asked for the sensitivity setting and then for measured data
it may not return data that represent voltages larger than the
sensitivity setting it "invented". There may even be situations, where
the module has no chance to find out if the arguments it gets passed for
a function are acceptable without determining the real state of the
device. If possible, incidents like this should be stored by the module
and the module should test at the time of device initialization if these
arguments were really acceptable and, if not, stop the experiment.


A typical example of this case are the settings for a "window" for the
digitizers, defining the part of a curve that gets returned or that is
integrated over etc. Because during the test run neither the time base
nor the amount of pre-trigger the digitizer is set to are known (unless
both have been set explicitely from the @code{EDL} script) it can't be
tested if the windows start and end positions are within the time range
the digitizer measures. Thus the module can just store these settings
and report to @code{fsc2} that they seem to be reasonable. Only when the
experiment starts and the module has its first chance of finding out the
time base and pre-trigger setting it can do the necessary checks on the
windows settings and should abort the experiment at the earliest
possible point if necessary.


To make things a bit easier when writing modules hook functions can be
defined within a module that get called automatically at the start of
the test run and after the test run finished successfully.


@node Third stage of interpretation, Reading the sources, Second stage of interpretation, Internals
@section Third stage of interpretation


In the third and final stage of the interpretation of an @code{EDL}
script the real experiment is run. This third stage may be repeated
several times if the user restarts an experiment without reloading the
@code{EDL} file.


At the start of the third stage the GPIB bus and the serial ports are
initialized (at least if one of the devices needs them). Next the hook
functions in the modules are called that allow the modules to initialize
the devices and do all checks they find necessary. If this was
successful the graphics for the experiment are initialized, opening up
the display windows. When all this has been done @code{fsc2} is ready to
do the experiment, i.e.@: to interpret the @code{EXPERIMENT} section.


But there is a twist. Just before starting to interpret the
@code{EXPERIMENT} section @code{fsc2} splits itself into two independent
processes by doing a @code{fork()}. If you use the @code{ps} command to
list all your running processes suddenly a new instance of @code{fsc2}
will be listed@footnote{Please note that already before the experiment
gets started you will find that there are three instances of @code{fsc2}
running, during the experiment there are (at least) four.}. The new
processes is doing the interpretation of the @code{EXPERIMENT} section,
i.e.@: is running the experiment, while one of the other processes is
responsible for the graphics and all interaction with the user.


The main reason for splitting the execution of the experiment into two
separate tasks is the following: the execution of the experiment, as far
as concerned with acquiring data from the devices etc.@: should be
unimpeded (at least as far as possible) from the task of dealing with
displaying data and user requests to allow maximum execution speed and
to make the timing of the experiment less dependent on user
interruptions. Take for example the case that the user starts to move
one of @code{fsc2}s windows around on the screen. As long as she is
moving the window no other instructions of the program get executed,
which effectively would stop the experiment for this time even though
nothing really relevant happens. By having one task for the actual
execution of the experiment and one for the user interaction this
problem vanishes because the task for the experiment can continue while
only the other task, responsible for the user interaction, is
blocked. This, of course, also applies to all other actions the user may
initiate, e.g.@: resizing of windows, magnification of data etc.


Another advantage is, of course, that on machines with more than one
processor the workload can be distributed on two processors.


The approach requires some channels of communication between the two
processes. Because the user interaction task has to draw the new data
the other task, executing the experiment, is producing they will have to
send from the experiment tasl to the user interaction task. And, the
other way round, the user interaction task must be able to send back
information received from the user (e.g.@: which file name got selected)
and to stop the experiment when the user hits the @code{Stop}
button. Care has been taken that this is done in a way that usually
can't be impeded by user interventions. The only exceptions are cases
where the further execution of the experiment depends on user input,
e.g.@: if within the experiment a new file has to be opened and the name
must be selected by the user.


The most important part of the communication between parent process (the
user interaction task) and the child process (the task running the
experiment) is basically a one-way communication -- the child process
must pass on newly acquired data to the parent process to be drawn. The
child processes writes the new data (together with the information where
they are to be drawn) into a shared memory segment and stores the key
for this memory segment in an unused slot in another buffer (that also
resides in shared memory). Then it sends the parent process a signal to
inform it that new data are available and continues immediately.


The user interaction process gets interrupted by the signal (even
while it is doing some other tasks on behalf of the user), removes and
stores the key for the memory segment, and can now deal with the new
data whenever it has the time to do so.


Problems can arise only if the child process for running the experiment
creates new data at a much higher rate than the parent can accept them,
in which case the buffer for memory segment keys would fill
up@footnote{The buffer is guarded against overflows by a semaphore that
is initialized to the number of slots in the buffer and on which the
child process does a down operation before writing data into the buffer
while the parent process posts it after removing an item.}. Only in this
case the child process will have to suspend the experiment until the
parent empties some of the slots for keys in the buffer. But,
fortunately, in practice this rarely happens. And as a further safeguard
against this happening the parent is written in a way that it will empty
slots in the buffer as fast as possible, if necessary deferring to draw
data or to react to user requests.


There is also a second communication channel for cases where the task
running the experiment needs some user input. Typical cases are requests
for file names, but also requests for information about the state of
objects in the toolbox. Here the task running the experiment always has
to wait for a reaction by the user interaction task (which in turn may
have to wait for user input). This communication channel is realized by
a pair of pipes between the processes.



@node Reading the sources, , Third stage of interpretation, Internals
@section Reading the sources


The following is supposed to give you an introduction on where to look
when you are searching for something in the source code of
@code{fsc2}. Of course, the program has gotten too complex to be
described easily (and with less space then required for the program
itself). Thus all I can try is showing you the red line through the
jungle of code along what's about to happen when @code{fsc2} is started,
an @code{EDL} script gets loaded, tested and finally executed. This is
yet far from complete but work in progress at best.


Lets start with what to do when you want to debug @code{fsc2}. It's
probably obvious that when you want to run the main (parent) process of
@code{fsc2} under a debugger you just start it within the debugger. To
keep the debugger from getting stopped each time an internally used
signal is received you probably should start with telling the debugger
to ignore the two signals @code{SIGUSR1} and @code{SIGUSR2}. Under
@code{gdb} you do this by entering
@example
(gdb) handle SIGUSR1 nostop noprint
(gdb) handle SIGUSR2 nostop noprint
@end example


Debugging the child process that runs the experiment requires the
debugger to attach to the newly created child process. To be able to do
so without the child process already starting to execute while you're
still in the process of attaching to it you should set the environment
variable @code{FSC2_CHILD_DEBUG}, e.g.@:
@example
jens@@crowley:~/Lab/fsc2> export FSC2_CHILD_DEBUG=1
@end example
@noindent
When this environment variable is defined (what you set it to doesn't
matter) the child process will sleep for about ten hour before it
starts, which should be more than enough for you to attach to
it. Moreover, when @code{FSC2_CHILD_DEBUG} is set a line telling you the
PID of the child process is printed out when the child process gets
started. All you have to do is to start the debugger with the PID to
attach to. Here's an example of a typical session where I start to debug
the child process using @code{gdb}:
@example
jens@@crowley:~/Lab/fsc2 > export FSC2_CHILD_DEBUG=1
jens@@crowley:~/Lab/fsc2 > src/fsc2 &
[2] 28801
jens@@crowley:~/Lab/fsc2 > Child process pid = 28805
jens@@crowley:~/Lab/fsc2 > gdb src/fsc2 28805
GNU gdb 5.0
Copyright 2000 Free Software Foundation, Inc.
GDB is free software, covered by the GNU General Public License, and you are
welcome to change it and/or distribute copies of it under certain conditions.
Type "show copying" to see the conditions.
There is absolutely no warranty for GDB.  Type "show warranty" for details.
This GDB was configured as "i386-suse-linux"...
/home/jens/Lab/fsc2/28805: No such file or directory.
Attaching to program: /home/jens/Lab/fsc2/src/fsc2, Pid 28805
Reading symbols from /usr/X11R6/lib/libforms.so.1...done.
Loaded symbols for /usr/X11R6/lib/libforms.so.1
Reading symbols from /usr/X11R6/lib/libX11.so.6...done.
Loaded symbols for /usr/X11R6/lib/libX11.so.6
Reading symbols from /lib/libm.so.6...done.
Loaded symbols for /lib/libm.so.6
Reading symbols from /lib/libdl.so.2...done.
Loaded symbols for /lib/libdl.so.2
Reading symbols from /usr/local/lib/libgpib.so...done.
Loaded symbols for /usr/local/lib/libgpib.so
Reading symbols from /lib/libc.so.6...done.
Loaded symbols for /lib/libc.so.6
Reading symbols from /usr/X11R6/lib/libXext.so.6...done.
Loaded symbols for /usr/X11R6/lib/libXext.so.6
Reading symbols from /usr/X11R6/lib/libXpm.so.4...done.
Loaded symbols for /usr/X11R6/lib/libXpm.so.4
Reading symbols from /lib/ld-linux.so.2...done.
Loaded symbols for /lib/ld-linux.so.2
Reading symbols from /lib/libnss_compat.so.2...done.
Loaded symbols for /lib/libnss_compat.so.2
Reading symbols from /lib/libnsl.so.1...done.
Loaded symbols for /lib/libnsl.so.1
Reading symbols from /usr/lib/gconv/ISO8859-1.so...done.
Loaded symbols for /usr/lib/gconv/ISO8859-1.so
Reading symbols from /usr/local/lib/fsc2/fsc2_rsc_lr.so...done.
Loaded symbols for /usr/local/lib/fsc2/fsc2_rsc_lr.so
Reading symbols from /usr/local/lib/fsc2/User_Functions.so...done.
Loaded symbols for /usr/local/lib/fsc2/User_Functions.so
0x40698951 in __libc_nanosleep () from /lib/libc.so.6
(gdb) handle SIGUSR1 nostop noprint
(gdb) handle SIGUSR2 nostop noprint
(gdb)
@end example
@noindent
(There may be even more lines starting with "@code{Reading symbols for}"
and "@code{Loading symbols from}" if your @code{EDL} script lists some
modules in the @code{DEVICES} section.) Now the child process will be
waiting at the very start of its code in the function @code{run_child()}
in the file @file{run.c}.


Please note that because @code{fsc2} is normally running as a setuid-ed
process you must not try to debug the already installed and setuid-ed
version (that's not allowed for security reason) but only a version
which belongs to you and for which you have unlimited execution
permissions. This might require that you temporarily change the
permissions to allow access by all users for all the device files (for
the GPIB board, the serial ports and, possibly, cards installed in the
computer and used by @code{fsc2}) of devices that are controlled by the
@code{EDL} script you use during debugging. Don't forget to reset the
permissions when you're done.


This point out of the way I'll now want to start a tour de force through
the sources. When @code{fsc2} is invoked it starts at the code in
@code{main()} in the file @file{fsc2.c}. After setting up lots of global
variables and checking the command line options it tries to connect to a
kind of daemon process or starts it if it's not already running.  This
daemon is taking care of situations where @code{fsc2} is running in
non-exclusive mode, i.e.@: more than instance of @code{fsc2} is to be
run at the same time, and it will tell new instances about what they are
allowed to do and what not to avoid more than one instance trying to
access the same devices at the same time. It also is supposed to remove
things like lock files, shared memory segments etc.@: should it ever
happen that @code{fsc2} crashes that badly that it isn't able to do it
itself.


When this hurdle has been taken the initialization of the graphics is
done. All the code for doing so is in the file @file{xinit.c}. You will
have to read a bit about the @code{Xforms} library to understand what's
going on there. Mostly it's loading a shared library for creating the
forms used by the program (there are two shared libraries,
@file{fsc2_rsc_lr.so} and @file{fsc2_rsc_hr.so}, which on is loaded
depends on the screen resolution and the comand line option
@code{-size}), evaluating the settings in the @file{.Xdefaults} and
@file{.Xresources} files, again setting up lots of global variables and
doing further checks on the command line arguments.


When this part was successful some further checks of the remaining
command line options are done and, if specified on the command line,
an @code{EDL} script is loaded. Now we're already near to start the
main loop of the program. But before this loop is entered another new
process is spawned that opens a socket (of type @code{AF_UNIX}) to
listen on incoming connections from external programs that want to send
@code{EDL} scripts to @code{fsc2} for execution. The code for spawning
this child process and the code for the child process itself is to be
found in the @file{conn.c}.


After this stage the main loop of the program is entered. It consists of
just these two lines:
@example
while ( fl_do_forms( ) != GUI.main_form->quit )
    /* empty */ ;
@end example
Everything else is hidden behind these two lines. What they do is to
wait for new events until the @code{Quit} button gets pressed. Possible
events are clicking on the buttons in the different form, but they don't
need to be mentioned in this loop because all buttons trigger callback
functions when clicked on. The remaining stuff in the @code{main()}
function is just cleaning up when the program quits and a few things for
dealing with certain circumstances.


When you want to understand what's really going on you will have to
start with figuring out what happens in the callback functions for the
different buttons. The simplest way to find out which callback functions
are associated with which functions is probably to use the
@code{fdesign} program coming with the @code{Xforms} library and
starting it on one of the files @file{fsc2_rsc_lr.fd} or
@code{fsc2_rsc_hr.fd}. From within it you can display all of the forms
used by the program and find out the names of the callback functions
associated with each element of the forms.


The callback functions for the buttons of the main form are mostly in
@file{fsc2.c}. I will restrict myself to the most important ones: The
@code{Load} button invokes the function @code{load_file()}, which is
quite forward -- it asks the user to select a new file, checks if it
exists and can be read and, if this tests succeed, loads the file and
displays it in the main browser.


Once a file has been read in the @code{Test} button gets activated.
When it gets clicked on the function @code{test_file()} gets invoked and
that's were things get interesting. As you will find over and over again
in the program is starts with lots of testing and adjustments of the
buttons of the main form. (Should you worry what the lines like
@example
notify_conn( BUSY_SIGNAL );
@end example
@noindent
and
@example
notify_conn( UNBUSY_SIGNAL );
@end example
@noindent
are about: they tell the child process listening for external
connections that @code{fsc2} is at the moment too busy to accept new
@code{EDL} scripts and then that it's again prepared to load such a
script.)


The real fun starts at the line
@example
state = scan_main( EDL.in_file, in_file_fp );
@end example
@noindent
which calls the central subroutine to parse and test the @code{EDL}
script. A good deal of the following is going to be concerned what's
happening here.


The function @code{scan_main()} is located in the file
@file{split_lexer.l}. This obviously isn't a normall @code{C} file but a
file from which the @code{flex} utility creates a @code{C} file. If you
don't know yet, @code{flex} is a tool that generates programs that
perfom pattern-matching on input text. That means that a program created
by @code{flex} will dissect an input text into the tokens according to
the rules of how these tokens are supposed to look like (as regular
expressions), defined in the @code{.l} file. And that's exactly what
needs to be done with an @code{EDL} script before it can later be
digested by @code{fsc2} (with the help of another tool, @code{bison}).


Before @code{scan_main()} starts tokenizing the input it does some
initalization of things that may be needed later on. This consists first
of setting up an internal list of built-in @code{EDL} functions and
@code{EDL} functions that might be spplied by modules by calling
@code{functions_init()} in the file @file{func.c}. Built-in functions
are all listed at the top of @file{func.c} and the list built from it
contains information about the names of the functions, the @code{C}
function that are to be called for the @code{EDL} functions, the number
of arguments, and in which sections of the program the functions are
allowed to be called. When @code{fsc2} is done with it's built-in
functions it appends to the list also the functions supplied by modules.
These are found in the @file{Functions} file in the @file{config}
subdirectory. To do so another @code{flex} tokenizer is invoked on this
file, which is generated by the code in @file{func_list_lexer.l}.


After assembling the list of functions @code{fsc2} also creates a list
of the registered modules. This is done by invoking the tokenizer
created from the file @file{devices_list_lexer.l} on the list of
all devices, @file{Devices} also in the @file{config} subdirectory.


When this succeeded @code{fsc2} is ready to start interpreting the input
@code{EDL} file. But there's a twist: it does not work directly with the
@code{EDL} file, but with a somewhat cleaned up version as has already
ben mentioned above. This cleaning up is done by invoking an external
utility, @code{fsc2_clean}, again a @code{flex} generated program from
the file @code{fsc2_clean.l}. This is done in the function
@code{filter_edl()} in @file{util.c}. The @code{fsc2_clean} utility is
started with its @code{stdin} redirected to the @code{EDL} input file
and its @code{stdout} redirected to a pipe, from which @code{fsc2} in
the following is reading the cleaned up version of the @code{EDL} file.


The tokenizer (or "lexer") created from @file{split_lexer.l} is rather
simple in that it just reads in the @code{EDL} code until it finds the
first section keyword (and this should be the first line the lexer gets
from @code{fsc2_clean}, which already removed all comments etc.). On
finding the first section keyword control is transfered immediately to
another lexer, that is specifically written for dealing with the syntax
of this section. And that's why there are that many further files to
generate @code{flex} scanners, i.e.@: files with names ending in
@code{.l}, for each section there's a different tokenizer. These are
in the sequence the resulting lexers usually get invoked:
@example
devices_lexer.l        DEVICES section
vars_lexer.l           VARIABLES section
assign_lexer.l         ASSIGNMENTS section
phases_lexer.l         PHASES section
preps_lexer.l          PREPARATIONS section
exp_lexer.l            EXPERIMENT section
@end example
@noindent
Each of these lexers only returns to the one from @file{split_lexer.l}
when it finds a new section label (or when an error is detected).


In a typical @code{EDL} script the first lexer getting involved is the
one for the @code{DEVICES} section, generated from
@file{devices_lexer.l}. This lexer is very simple because all the
@code{DEVICES} section may consist of is a list of device names,
separated by semicolons. The only thing of interest is that when the end
of the @code{DEVICES} section is reached it invokes the function
@code{load_all_drivers()} from the file @code{loader.c}, which is
central to the plugin-like architecture of device handling in
@code{fsc2}.


The first part of @code{load_all_drivers()} consists of loading the
libraries for the devices listed in the @code{DEVICES} section (plus
another one called @code{User_Functions.so}) and then trying to find the
(non-builtin) functions in the libraries that are listed in the
@file{Functions} file in the @file{config} subdirectory, which already
has been read in. This is done in the @code{load_functions} subroutine.
Here first a library gets loaded (using @code{dlopen(3)}), and if this
succeeds, the function tries to determine the addresses of the hook
functions (see the next chapter about writing modules for what the hook
functions are good for in detail, it should suffice to say that these
are (optional) functions in the modules that get executed at certain
points during the execution of the @code{EDL} script, i.e.@: after the
library has been loaded, before and after the test run, before and after
the start of the experiment and, finally, just before the modules gets
unloaded). Then @code{fsc2} runs through its list of non-builtin
functions and checks if some of them can be found in the library.


This last step is getting a bit more complicated by the fact that it is
possible to load two or more modules with the same type (e.g.@: two
modules for lock-in amplifiers), which both will supply functions of the
same names. This is handled by each library defining a global variable,
a string, with the device type. When @code{fsc2} finds that there are
two or more devices with the same type (according to this global
variable), it will accept functions of the same name more than one time
and make the names unique by appending a hash ("@code{#}") and a number
for the device. So, if there are the modules for two lock-in amplifiers
listed in the devices section, both supplying a function
@code{lockin_get_data()}, it will create two entries in its internal
list of non-builtin functions, one named @code{lockin_get_data#1()} and
associated with the first lock-in amplifier in the @code{DEVICES}
section and one named @code{lockin_get_data#2()} for the second
lock-in. The first, addressing the first lock-in, can then be called as
either @code{lockin_get_data#1()} (or also without the "@code{#1}"),
while for @code{lockin_get_data#2()} the function from the library for
the second lock-in amplifier is used.


After all device libraries have been loaded successfully the functions
@code{init_hook()} in all modules that have such a function are invoked,
always in the same sequence as they were listed in the @code{DEVICES}
section. The modules can use thos hook function to initialize
themselves.


After this the work for of the @code{load_all_drivers()} and also the
lexer for the @code{DEVICES} section is done and control returns to the
lexer generated by @file{split_lexer.l} to the function
@code{section_parser()}. The last thing the lexer for the @code{DEVICES}
section did was setting a variable that tells this function what is the
next section in the @code{EDL} code. All the function now does is
transfer control to the lexer for that section.


Normally, the next section will be the @code{VARIABLES} section and the
lexer generated from @code{vars_lexer.l} takes over. This one is a bit
more interesting because the syntax of the @code{VARIABLES} section is
quite a bit more complicated than that of the @code{DEVICES} section.
This also makes it necessary not only to use a lexer but also a parser,
generated by the @code{bison} tool from the @file{vars_parser.y}. Both
the lexer and the parser work hand in hand to make sense from the
@code{EDL} code, the lexer spliting up the input into single tokens and
passing them on to the parser one by one, which in turn figures out if
the tokens make sense in th sequence they are coming in and then
executing some @code{C} code associated with. If you don't know yet how
lexers like @code{flex} and @code{lex} and parsers like @code{bison} and
@code{yacc} work and how they can be combined to interpret input you
should start trying to find out, @code{fsc2} strongly relies on them and
you probably will have lots of problems unerstanding much of the
following without at least some basic knowledge about them.


@code{fsc2} maintains a linked list of all variables and these list is
assembled from the code in the @code{VARIABLES} section. So this may be
a good place to give an introduction about how variables look like. All
variables are structures of type @code{Var}, which is declared (and
typedef-ed) in the file @file{variables.h} (you may prefer to look it up
now). It contains a string pointer for the variable name, a member for
the type of the variable, an union for the value of the variable (since
there are several types of variables they can have values of quit a
range of types). Further, there are some data to keep track of array
variables (1- or multi-dimensional) and a member for certain
flags. Finally, there are pointers to mae the variable structure fit
into a (doubly) linked list.

Before going into more details here's a list of the possible variable
types:
@example
UNDEF_VAR
STR_VAR
INT_VAR
FLOAT_VAR
INT_ARR
FLOAT_ARR
INT_REF
FLOAT_REF
INT_PTR
FLOAT_PTR
REF_PTR
FUNC
@end example
@noindent
Each variable begins its life with type @code{UNDEF_VAR}. But usually it
should become promoted to something more usful shortly afterwards, so
you will find it only in rare cases (it's sometimes used for temporary
variables, we're going to discuss temporary variables sometime later). A
@code{STR_VAR} is a variable holding a string, and also this type of
variables only wil be found in temporary variables. What an
@code{INT_VAR} and @code{FLOAT_VAR} is will probably be quite obvious,
these types of variables can hold a single (long) integer or floating
point (double) value, which are stored in the @code{lval} and
@code{dval} members of the @code{val} union of the @code{Var} structure.


Variables of type @code{INT_ARR} and @code{FLOAT_ARR} are for holding
one-dimensional arrays of integer and floating point values.  For
variables of thess types the @code{len} field of the @code{Var}
structure will contain the (current) length of the array and the
@code{lpnt} and @code{dpnt} members of the @code{val} union are pointers
to the array with its values.

Variables of type @code{INT_REF} and @code{FLOAT_REF} are for
multidimensional arrays. These are a bit different because they don't
store any elements of the array directly but instead pointers to lower
dimensional arrays. These might again be multdimensional array variables
(but with one dimension less) or @code{INT_ARR} or @code{FLOAT_ARR}
variables, that then contain the data of an one-dimensional array. To
make clearer what I mean lets assume that you define a 3-dimensional
array called @code{A} in the @code{VARIABLES} section:
@example
A[ 4, 2, 7 ];
@end example
@noindent
This will result in the creation of 9 variables. The top-most one (and
only one that can be accessed directly from the @code{EDL} script
because it's the only one having a name) is of type @code{INT_REF} and
contains an array of 4 pointers to 2x7-dimensional arrays, stored in the
@code{vprtr} member of the @code{val} union of the @code{Var}
structure. It's @code{dim} member is set to 3 since it's a 3-dimensional
variable and the @code{len} member gets set to 4 because the
@code{val.vptr} field is an array of 4 @code{Var} pointers.  Each of the
4 @code{Var} pointers stored in the @code{val.vptr} field point to a
different variable, of which each is a again of type @code{INT_REF}.
But these variables pointed to will have a dimension of 2 only, so the
@code{dim} memberis set to 2 and since each is of dimension @w{@code{[2,
7]}}, their @code{len} members are set to 2. And each of this
lower-dimension variables again will have the @code{val.vptr} array
consist of (2) pointers pointing to one.dimensional arrays, this time of
type @code{INT_ARR}. These @code{INT_ARR} variables, two levels below
the original variable named @code{A} will each contain an array of 7
integer values, pointed to by @code{val.lpnt}.


When you count the variables actually created according to the scheme
above you will find that it are 9, one for the variable named @code{A}
itself, which in turn points to 4 newly created variables, of which each
again points to 2 further variables (which finally contain all the data
as one-dimensional arrays).


The remaining variable types @code{INT_PTR}, @code{FLOAT_PTR},
@code{REF_PTR} and @code{FUNC} are again only used with temporary
variables and will be discussed below.


The variables declared in the @code{VARIABLES} section are all elements
of a doubly linked list. The pointer to the top element is a member of
the global @code{EDL} variable. It's a structure of type
@code{EDL_Stuff} declared in @file{fsc2.h} and countaining data relevant
for the @code{EDL} script currently under execution. To find the first
element of the list of variables see the @code{EDL.Var_List} member.
Directly beneath it you will find that there's also a second variable
named @code{EDL.Var_Stack}. This variable is also doubly linked list of
variables, but in contrast this list is for temporary variables, which
get created and deleted all of the time during the interpretation of an
@code{EDL} script and is in the following often referred to as the
"stack". In this list also the types of variables that were only
mentioned en passant above can be found, which I will shortly summarize
here.


A variable of type @code{STR_VAR} gets created whenever in the text of
the @code{EDL} script a string is found or when an @code{EDL} function
returns a string. Since strings are always used shortly after their
creation (always within the statement they appear in) they are always
temporary variables. Variable of type @code{INT_PTR} and
@code{FLOAT_PTR} are variables in which the @code{val.lpnt} and
@code{val.dpnt} members point to arrays belonging to some other
variable, but never to the variable itself. Variables of type
@code{REF_PTR} are variables in which the @code{from} member (which
hadn't been mentioned yet) pointing to the variable it's pointing to.
Finally, variables of type @code{FUNC} have the @code{val.fcnt} member
pointing to address to one of the @code{C} functions that get called
for @code{EDL} functions.


After this short detour about variables back to what happens in the
@code{VARIABLES} section. In the most simple case the @code{VARIABLES}
section isn't much more than a list of variable names, which need to be
created. When the lexer finds something which looks like a variable name
(i.e.@: a word starting with a letter, followed by more letters, digits
or underscore characters), it will first check if a variable by this
name already exists by calling the function @code{vars_get()} from
@file{variables.h} with the name it found. It either receives a pointer
to the variable or @code{NULL} if the variable does not exist yet. In
the latter it will create a new variable by calling @code{vars_new()}
(which returns a pointer to the new variable). It then passes the
variables address to the parser. Assuming the variable has been newly
created it will still be of type @code{UNDEF_VAR} and it's not clear yet
if it's a simple variable or going to be an array. Thus the parser asks
the lexer for the next token. If this is a comma or a semicolon it can
conclude that the variable is a simple variable and can set its type to
either @code{INT_VAR} or @code{FLOAT_VAR} (depending on its name
starting with a lower or upper case character) and is done with it. But
if the next token is a "@code{[}" the parser can only notice that this
is going an array and must ask the lexer for more tokens, which should
be a list of numbers, separated by commas and ending in a "@code{]}"
(but there are even more complicated cases). When all these have been
read in the parser calls some @code{C} code that sets up the new array
according to the list of sizes the parser received. More complicated
cases may include that instead of a number an asterisk ("@code{*}") is
found, in which case the array has to be initialized in a way to
indicate that the array hasn't been fully specified yet (this is done by
setting the @code{len} field of the variable structure for the array to
0 and setting the @code{IS_DYNAMIC} flag in the @code{flags} member).


Other complications may include that a size if an array isn't given as a
number but as an arithmetic expression, possibly involving already
defined (and initialized) variables, arithmetic operators or even
function calls. In the hope not to bore you to death by getting too
detailed I want to describe shortly how the parser evaluates such an
epression because it's more or less the same all over the complete
program, not restricted to the @code{VARIABLES} section. Let's discuss
things using the following example
@example
abs( R + 5 * ( 2 - 7 ) )
@end example
@noindent
Here the lexer will first extract the "@code{abs}" token. Now I have to
admit a white lie I made above: I said that the lexer will check first
for tokens like this if it's an already existing variable. But it
actually first checks if it's an @code{EDL} function name, only if it
isn't it will check if it's a variable. And here it will find that
@code{abs} is a function by calling the function @code{func_get()} in
@file{func.c}. This function will return the address of a new temporary
variable on the stack (pointed to by @code{EDL.Var_Stack}) of type
@code{FUNC} with the @code{val.fcnt} holding the address of the function
to be executed for the @code{abs()} @code{EDL} function (which is
@code{f_abs()} in @file{func_basic.c}). The lexer now passes the address
of the variable on to the parser.


The parser knows that functions always have to be followed by an opening
parenthesis and thus will ask the lexwer for the next token. If this
isn't a "@code{(}" the parser will give up, complaining about a syntax
error. Otherwise the parser has to look out for the function
argument(s), asking the lexer for more tokens. The next one it gets is a
pointer to the (hopefully already defined and initialized) variable
"@code{R}". But it doesn't know yet if this is already the end of the
(first) argument, so it requests another token, which is the "@code{+}".
From this the parser concludes that it obviously hasn't seen the end of
it yet and gets itself another token, the "@code{5}". A stupid parser
might now add the 5 to the value of @code{R}, but since the parser knows
the precedence od operators it has to defer this operation at least
until it has seen the next token. When the next token would be a comma
(indicating that a new function argument starts) or a closing
parenthesis it would now do the addition. But since the next token is a 
"@code{*}" it has to wait and first evaluate the "@code{( 2 - 7 )}"
part and multiply the result with 5 before again checking if it's prudent
to add the result to the value of @code{R}. Since the next token the
parser receives from the lexer is the "@code{)}, indicating the end of
the function arguments, it can go on, adding the result of
@w{"@code{5 * ( 2 - 7 )}"} to the value of @code{R}. In this process
the temporary variable holding the pointer to the variable @code{R} gets
popped from the stack and a new variable with the result of the
operation is pushed onto the stack (i.e.@: is added to the end of the
linked list of variables making up the stack). Now the stack still
contains two variables, the variable pointing to the @code{f_abs()}
function and the variable with the function argument. And since the
parser has seen from the "@code{)}" that no more arguments are to be
expected for the function it will invoke the @code{f_abs()} function
with a pointer to the variable with the function argument.


If you cared to look it up you will have found that the @code{f_abs()}
function is declared as
@example
Var *f_abs( Var *v );
@end example
@noindent
This is typical for all functions that are invoked on behalf of
@code{EDL} functions: they always expect a single argument, a pointer to
a @code{Var} structure and always return a pointer to such a structure.
The pointer these functions receive is always pointing to the first
argument of the function. If the function requires more than one
argument it has to look for the @code{next} member of the variable,
and if this isn't @code{NULL} it points to the next argument. Of course,
zthis can be repeated until in the last argument the @code{next} field
is @code{NULL}. The function now has to check if the types of the
variables are what is required (it e.g.@: wouldn't make sense for the
@code{f_abs()} function if the argument would be a variable of type
@code{STR_VAR}) and if there are enough arguments (at least if the
function allows a variable number of arguments, if the function is
declared to accept only a fixed number of arguments these cases will be
dealt with before the function is ever called, see below).


The function now has to do it's work and, when it's done, creates
another temporary variable on the stack with the result (this is done by
a call of the function @code{vars_push()} in @file{variables.c}). In the
process it may remove the function arguments from the stack (using
@code{vars_pop()} also in @file{variables.c}), if it doesn't do so it
will be done automatically when the function returns. Note that there's
a restriction in that a function never can return more than a pointer to
a single variable, i.e. the variable pointed to must have its
@code{next} member set to @code{NULL}, being the last variable on the
stack. A function may also chose to return @code{NULL}, but it's good
practice to always return a value, if there isn't really anything to be
returned, i.e.@: the function always get invoked for its side effects
only, it should simply return an integer variable with a value of 1 to
indicate that it succeeded.


Again I have to admit that I wasn't completely honest when I wrote above
that "the parser invokes the @code{f_abs()} function". The parser does
not call the @code{f_abs()} function directly, but instead calls
@code{func_call()} in @file{func.c} instead with a pointer to the
variable of type @code{FUNC} pointing to the @code{f_abs()} function
(please remember that the function argument(s) are coming directly after
this variable on the stack). Before @code{func_call()} really calls
@code{f_abs()} it will first do several checks. The first one is to see
if the variable it got is really pointing to a function. Then it checks
how many arguments there are and compares it to the number of arguments
the function to be called is prepared to accept. If there are too many
it will strip of the superfluous one (and print out a warning), if there
aren't enough it will print out an error message and stop the
interpretation of the @code{EDL} script. If these tests show that the
function can be called without problems @code{func_call()} still has to
create an entry on another stack (the "call stack") that keeps track of
situations where during the execution of a function another function is
called etc., which is e.g.@: needed for emitting reasonable error
messages. Only then the @code{f_abs()} is called. When @code{f_abs()}
returns, the @code{func_call()} first pops the last element from the
"call stack", automatically removes what's left of the function
arguments and the variable with the pointer to the @code{f_abs()}
function (always checking that the called function hasn't messed up
stack in unrecoverable ways) before it returns the pointer with the
result of the call of @code{f_abs()} to the parser.


Now the parser will at last know what's the result of 
@example
abs( R + 5 * ( 2 - 7 ) )
@end example
@noindent
and can use it e.g.@: as the length of a new array.


Of course, beside being defined new variables they can also become
intialized in the @code{VARIABLES} section. The values used in the
initialization can, of course, also be the results of complicated
expressions. But these will be treated in exactly the same way as
already described above, the only new thing is the assignment part. The
parser knows that a variable is getting initialized when it sees the
"@code{=}" operator after the definition of a variable. It then parses
and interprets the right hand side of the equation and finally assigns
the result to the newly defined variable on the left hand side. To do so
which it calls the function @code{vars_assign()} from @file{variables.c}
(if it's an initialization of an array also some other functions get
involved in between).


The creation and initialization of one- and more-dimensional arrays
makes up a good deal of the code in @file{variables.c}. Unfortunately,
so many things have to be taken care of that it can be quite a bit of
work understanding what's going on and I have to admit that it usually
also takes me some time to figure out what (and why) I have written
there, so don't worry in case you have problems understanding everything
at the first glance...


But after all these detours let's get back to the red line and continue
with what happes during the interpretation of an @code{EDL} script. I
guess most of what can be said about the @code{VARIABLES} section has
been said and we should assume that we reached the end of this section.
The lexer generated from @file{vars_lexer.l} will then retransfer
control to the lexer created from @file{split_lexer.l}, returning a
number indicating what is the type of the next section.





That's how far I got yet, a sequel is coming soon, stay tuned ;-)

@c $Id$
@c
@c Copyright (C) 1999-2003 Jens Thoms Toerring
@c
@c This file is part of fsc2.
@c
@c Fsc2 is free software; you can redistribute it and/or modify
@c it under the terms of the GNU General Public License as published by
@c the Free Software Foundation; either version 2, or (at your option)
@c any later version.
@c
@c Fsc2 is distributed in the hope that it will be useful,
@c but WITHOUT ANY WARRANTY; without even the implied warranty of
@c MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
@c GNU General Public License for more details.
@c
@c You should have received a copy of the GNU General Public License
@c along with fsc2; see the file COPYING.  If not, write to
@c the Free Software Foundation, 59 Temple Place - Suite 330,
@c Boston, MA 02111-1307, USA.


@node Internals, Modules, Cloning Devices, Top
@chapter Internals


In this chapter I will try to explain in some more detail how
@code{fsc2} works internally. I hope that this will help especially if
you're going try to write a new module for a device (or if you get upset
about things @code{fsc2} does differently from the way you would like it
to).


As you will already have understood, @code{fsc2} is basically an
interpreter for @code{EDL} scripts. Normal interpreters interpret each
line of input individually, i.e.@: analyze a line, and, if the line is
syntactically correct, execute it. That's what @code{fsc2} also does,
but only for the parts before the @code{EXPERIMENT} section. In
contrast, the interpretation of the @code{EXPERIMENT} section of an
@code{EDL} file consists of several steps. In the first step the
@code{EXPERIMENT} section as a whole is read in and only syntax checks
are done. In the second step a complete test run of @code{EXPERIMENT}
section of the script is done to avoid that the experiment will have to
be stopped due to obvious logical errors in the @code{EDL} script. The
device modules are involved, i.e.@: they already can do all kinds of
checks on what can be expected to happen during the real experiment and
detect possible problems.


Only if all these tests succeeded the third step, the execution of the
@code{EXPERIMENT} section of the @code{EDL} script, is started, i.e.@:
the experiment is run. When an experiment is restarted (without
reloading the @code{EDL} file) only this third step is repeated.


@ifinfo
@menu
* First stage of interpretation::
* Second stage of interpretation::
* Third stage of interpretation::
* Reading the sources::
@end menu
@end ifinfo


@node First stage of interpretation, Second stage of interpretation, Internals, Internals
@section First stage of interpretation


In the first stage of the interpretation the script is read in a token
by token fashion, where tokens are e.g.@: variable or function names,
numbers, braces, semicolons, section labels etc. This is mainly done by
the code within the files which you'll find in the @file{src} directory,
having an extension of @code{.l}. As you will see there's such a file
for each of the different sections an @code{EDL} script may
contain. Actually, there are some extra ones, @file{split_lexer.l} is
the central switch for the first stage that calls the individual
tokenizers in turn on finding a new section label and also deals with
error conditions that couldn't be handled by the section
interpreters. Two extra tokenizers, @file{devices_list_lexer.l} and
@file{func_list_lexer.l} are for analyzing the files with the list of
device modules, @file{conf/Devices}, and the list of functions,
@file{conf/Functions} (they also contain some additional @code{C} code
for interpreting the tokens).


Finally, there is @file{fsc2_clean.l}. @code{EDL} itself expects its
input to be a single file in a certain format. Thus it does not deal
directly with the input files (there can be more than one when there are
@code{#INCLUDE} statements in an @code{EDL} script). Therefore, there's
an extra program, @file{fsc2_clean} that translates the input @code{EDL}
script into a form that the main program understands. @code{fsc2_clean}
for example removes all comments, includes files for @code{#INCLUDE}
statements, adds information about line numbers and file names, deals
with physical units etc.@:, and then passes this cleaned-up input to
@code{fsc2}. If you are interested what @code{fsc2} really sees of an
@code{EDL} file you can run @code{fsc2_clean} with the @code{EDL} file
as its standard input, i.e.@:
@example
fsc2_clean < edl_script.edl
@end example
@noindent
(please note that the output of @code{fsc2_clean} program contains some
non-printable characters).


The lines of @code{EDL} script in the sections preceeding the
@code{EXPERIMENT} section are executed immediately. E.g.@: during the
handling of the @code{DEVICES} section the modules for the listed
devices are loaded and the functions defined in the modules are included
into @code{fsc2}s internal list of functions that can be used from
within the @code{EDL} script. While reading the @code{VARIABLES} section
the newly defined variables are added to @code{fsc2}s list of variables,
and, if necessary, initialized.


While the tokenizers (i.e.@: the files with an extension of @code{.l})
are used for splitting of the input into manageable tokens, the
execution of the code (now consisting of a stream of tokens) is done in
the files with an extension of @code{.y} (or, to be precise, by the code
generated from these files). In these files, the parsers, actions
(mostly a few lines of @code{C} code) are executed for syntactically
correct sets of tokens. Because actions can only be executed for input
with valid syntax, these files practically define what is syntactically
correct and what is not.


To give you an example, here's a very simple statement from an
@code{EDL} script:
@example
a = B_x + 3;
@end example
The tokenizer doesn't has too much to do in this case, it will output a
list of the tokens of this line, together with some information about the
class the individual tokens belong to. So, it will pass the following
kind of information to the parser:
@example
Floating point variable named 'a'
Equal operator
Integer variable named 'B_x'
Plus operator
Integer number with a value of 3
End of statement character: ;
@end example
@noindent
The parser, in turn, has a list of all syntactically correct
statements@footnote{Actually, the parser does not really has a list of
all syntactically correct statements but contains a set of rules that
define exactly how such statements may look like. One of these rules for
example is that a variable name and an equal operator may be followed by
either a variable, a function call or an integer or floating point
number. Anything not fitting this pattern is a syntax error.}, together
with the information what to do for these statements. One of the rules
is that a statement consisting of sequence of the tokens
@example
Variable, Equal operator, Variable, Plus operator,
integer number, end of statement character
@end example
@noindent
is syntactically correct and that for this sequence of tokens some
@code{C} code has to be executed that fetches the value of the variable
@code{B_x}, adds it to the integer number and finally stores the result
into the variable @code{a}. Statements that are not in the parsers list
are @i{per definitionem} syntactically incorrect. For example, there is
no rule on how to deal with a sequence of tokens as the one above but
with the integer number missing. Because the parser looks at the
statements token by token it won't complain while getting the first four
tokens up to and including the plus operator. Only if the end of
statement operator, the semicolon, is found directly after the plus sign
it will recognize that there is no rule on how to deal with the
situation, print the error message @code{Syntax error near token ';'}
(plus the file name and line number) and abort.


The @code{EXPERIMENT} section is handled differently. Most important,
the code of the @code{EXPERIMENT} section is not executed at this
stage. It is just split up into its tokens and only some rudimentary
syntax check is done, e.g.@: undefined variables or mismatched braces
etc.@: are detected. Instead, an internal list of all the tokens the
@code{EXPERIMENT} section consists of is created. This list is later
used to test and execute the @code{EXPERIMENT} section.


Writers of modules should know that the modules already get loaded when
the @code{DEVICES} section (which always must be the first section) is
dealt with. A module may contain a special function, called a hook
function, that automatically gets called when the module has just been
loaded.  This allows for example to set the internal variables of the
module to a well-defined state. This function may not call any functions
accessing the device because neither the GPIB bus nor the serials ports
(or any other devices like ISA or PCI cards) are configured at this
moment.


While handling the part of the @code{EDL} script up to the start of
the @code{EXPERIMENT} section, functions from the modules may be called
(unless they have been explicitely declared to be used only during the
experiment). Usually such function calls will be used to define the
state of the device at the start of the experiment. For example, the
@code{PREPARATIONS} section may contain a line like
@example
lockin_sensitivity( 100 uV );
@end example
@noindent
When @code{fsc2} interprets this line it will call the appropriate
function in the module for the lock-in amplifier with a floating point
number of @code{0.0001} as the argument (the module does not have to
take care of dealing with units, they are already translated by
@code{fsc2}, or, to be precise, by @code{fsc2_clean}).  The module
function for setting the lock-in amplifiers sensitivity should now check
the argument it got passed (there may or may not be a sensitivity
setting of @code{0.0001} and only the module knows about this). If the
argument is reasonable the module should store the value as to be set
when the lock-in amplifier finally gets initialized at the start of the
experiment.


How to deal with wrong arguments or arguments that don't fit (e.g.@: if
the argument is @code{40 uV} but the lock-in amplifier has only
sensitivity settings of @code{30 uV} and @code{100 uV}) is completely up
to the writer of the module, @code{fsc2} will accept whatever the module
returns. For example, the module may accept the argument after changing
it to something to the next possible sensitivity setting and printing
out a warning or it may bail out and tell @code{fsc2} to stop
interpreting the @code{EDL} script.


Another thing module writers should keep in mind is that this first (and
also the second) stage is only run once, while the experiment itself may
be run several times. Thus it is important that the values with which a
device must be initialized at the start of an experiment are stored in a
way that they aren't overwritten during the experiment. For example, it
does not suffice to have one single variable for the lock-in amplifiers
sensitivity because the sensitivity and thus the variable might get
changed during the experiment.


@node Second stage of interpretation, Third stage of interpretation, First stage of interpretation, Internals
@section Second stage of interpretation


The second stage of the interpretation of an @code{EDL} script is
the test run of the @code{EXPERIMENT} section. A test run is necessary
for two reasons. First, only a very rudimentary syntax check has been
done for the @code{EXPERIMENT} section until now. Second, and much more
important, the script may contain logical errors and it would be rather
annoying if these would only be found after the experiment had already
been run for several hours, necessitating the premature end of the
experiment. For example, without a "dry" run it could happen that only
after a long time it is detected that the field of the magnet is
requested to be set to a value that the magnet can't produce. In this
case there usually are only few alternatives, if any, to aborting the
experiment. Foreseeing and taking the appropriate measures for such
possibly fatal situation would complicate both the writing of modules
and @code{EDL} scripts enormously and probably would still not catch
all of them.


By doing a test run, on the other hand, for example the function for
setting the magnet to a new field will be called with all values that
are to be expected during the real experiment and thus invalid field
settings can be detected in advance. Doing a test run is much faster
than running the experiment itself because during the test run the
devices will not be accessed (which usually uses at least 90% of the
whole time), calls of the @code{wait()} function do not make the program
sleep for the requested time, no graphics are drawn etc.


The writers of modules have an important responsibility to make running
the test run possible. During the test run the devices can't be
accessed. Despite this the modules have to deal in a reasonable way with
requests for returning data from the devices. Thus the modules must,
during the test run, "invent" data for the real ones. This can be a bit
tricky and special care must be taken to insure that these "invented"
data are consistent. For example, if a module for a lock-in amplifier
first gets asked for the sensitivity setting and then for measured data
it may not return data that represent voltages larger than the
sensitivity setting it "invented". There may even be situations, where
the module has no chance to find out if the arguments it gets passed for
a function are acceptable without determining the real state of the
device. If possible, incidents like this should be stored by the module
and the module should test at the time of device initialization if these
arguments were really acceptable and, if not, stop the experiment.


A typical example of this case are the settings for a "window" for the
digitizers, defining the part of a curve that gets returned or that is
integrated over etc. Because during the test run neither the time base
nor the amount of pre-trigger the digitizer is set to are known (unless
both have been set explicitely from the @code{EDL} script) it can't be
tested if the windows start and end positions are within the time range
the digitizer measures. Thus the module can just store these settings
and report to @code{fsc2} that they seem to be reasonable. Only when the
experiment starts and the module has its first chance of finding out the
time base and pre-trigger setting it can do the necessary checks on the
windows settings and should abort the experiment at the earliest
possible point if necessary.


To make things a bit easier when writing modules hook functions can be
defined within a module that get called automatically at the start of
the test run and after the test run finished successfully.


@node Third stage of interpretation, Reading the sources, Second stage of interpretation, Internals
@section Third stage of interpretation


In the third and final stage of the interpretation of an @code{EDL}
script the real experiment is run. This third stage may be repeated
several times if the user restarts an experiment without reloading the
@code{EDL} file.


At the start of the third stage the GPIB bus and the serial ports are
initialized (at least if one of the devices needs them). Next the hook
functions in the modules are called that allow the modules to initialize
the devices and do all checks they find necessary. If this was
successful the graphics for the experiment are initialized, opening up
the display windows. When all this has been done @code{fsc2} is ready to
do the experiment, i.e.@: to interpret the @code{EXPERIMENT} section.


But there is a twist. Just before starting to interpret the
@code{EXPERIMENT} section @code{fsc2} splits itself into two independent
processes by doing a @code{fork()}. If you use the @code{ps} command to
list all your running processes suddenly a new instance of @code{fsc2}
will be listed@footnote{Please note that already before the experiment
gets started you will find that there are three instances of @code{fsc2}
running, during the experiment there are (at least) four.}. The new
processes is doing the interpretation of the @code{EXPERIMENT} section,
i.e.@: is running the experiment, while one of the other processes is
responsible for the graphics and all interaction with the user.


The main reason for splitting the execution of the experiment into two
separate tasks is the following: the execution of the experiment, as far
as concerned with acquiring data from the devices etc.@: should be
unimpeded (at least as far as possible) from the task of dealing with
displaying data and user requests to allow maximum execution speed and
to make the timing of the experiment less dependent on user
interruptions. Take for example the case that the user starts to move
one of @code{fsc2}s windows around on the screen. As long as she is
moving the window no other instructions of the program get executed,
which effectively would stop the experiment for this time even though
nothing really relevant happens. By having one task for the actual
execution of the experiment and one for the user interaction this
problem vanishes because the task for the experiment can continue while
only the other task, responsible for the user interaction, is
blocked. This, of course, also applies to all other actions the user may
initiate, e.g.@: resizing of windows, magnification of data etc.


Another advantage is, of course, that on machines with more than one
processor the workload can be distributed on two processors.


The approach requires some channels of communication between the two
processes. Because the user interaction task has to draw the new data
the other task, executing the experiment, is producing they will have to
send from the experiment tasl to the user interaction task. And, the
other way round, the user interaction task must be able to send back
information received from the user (e.g.@: which file name got selected)
and to stop the experiment when the user hits the @code{Stop}
button. Care has been taken that this is done in a way that usually
can't be impeded by user interventions. The only exceptions are cases
where the further execution of the experiment depends on user input,
e.g.@: if within the experiment a new file has to be opened and the name
must be selected by the user.


The most important part of the communication between parent process (the
user interaction task) and the child process (the task running the
experiment) is basically a one-way communication -- the child process
must pass on newly acquired data to the parent process to be drawn. The
child processes writes the new data (together with the information where
they are to be drawn) into a shared memory segment and stores the key
for this memory segment in an unused slot in another buffer (that also
resides in shared memory). Then it sends the parent process a signal to
inform it that new data are available and continues immediately.


The user interaction process gets interrupted by the signal (even
while it is doing some other tasks on behalf of the user), removes and
stores the key for the memory segment, and can now deal with the new
data whenever it has the time to do so.


Problems can arise only if the child process for running the experiment
creates new data at a much higher rate than the parent can accept them,
in which case the buffer for memory segment keys would fill
up@footnote{The buffer is guarded against overflows by a semaphore that
is initialized to the number of slots in the buffer and on which the
child process does a down operation before writing data into the buffer
while the parent process posts it after removing an item.}. Only in this
case the child process will have to suspend the experiment until the
parent empties some of the slots for keys in the buffer. But,
fortunately, in practice this rarely happens. And as a further safeguard
against this happening the parent is written in a way that it will empty
slots in the buffer as fast as possible, if necessary deferring to draw
data or to react to user requests.


There is also a second communication channel for cases where the task
running the experiment needs some user input. Typical cases are requests
for file names, but also requests for information about the state of
objects in the toolbox. Here the task running the experiment always has
to wait for a reaction by the user interaction task (which in turn may
have to wait for user input). This communication channel is realized by
a pair of pipes between the processes.



@node Reading the sources, , Third stage of interpretation, Internals
@section Reading the sources


The following is supposed to give you an introduction on where to
look when you are search for something in the source code of
@code{fsc2}. This is yet far from complete but work in progress.


Lets start with what to do when you want to debug @code{fsc2}. It's
probably obvious that when you want to run the main (parent) process of
@code{fsc2} under a debugger you just start it in the debugger. To keep
the debugger from getting stopped each time an internally used signal is
received you probably should start with telling the debugger to ignore
the two signals @code{SIGUSR1} and @code{SIGUSR2}. Under @code{gdb} you
do this by entering
@example
(gdb) handle SIGUSR1 nostop noprint
(gdb) handle SIGUSR2 nostop noprint
@end example


Debugging the child process, running the experiment, requires the
debugger to attach to the newly created child process. To be able to do
so without the child process already starting to execute while you're
still trying to attach it you should set the environment variable
@code{FSC2_CHILD_DEBUG}, e.g.@:
@example
> export FSC2_CHILD_DEBUG=1
@end example
@noindent
When this environment variable is defined the child process will sleep
for about ten hour before it starts, which should be more than enough
for you to attach to it. Moreover, when this environment variable is set
a line telling you the PID of the child process is printed out when the
child process gets started. All you have to do is to start the debugger
with the PID to attach to. Here's an example of a typical session
when I start try to debug the child process using @code{gdb}:
@example
jens@@crowley:~/Lab/fsc2 > export FSC2_CHILD_DEBUG=1
jens@@crowley:~/Lab/fsc2 > src/fsc2 &
[2] 28801
jens@@crowley:~/Lab/fsc2 > Child process pid = 28805
jens@@crowley:~/Lab/fsc2 > gdb src/fsc2 28805
GNU gdb 5.0
Copyright 2000 Free Software Foundation, Inc.
GDB is free software, covered by the GNU General Public License, and you are
welcome to change it and/or distribute copies of it under certain conditions.
Type "show copying" to see the conditions.
There is absolutely no warranty for GDB.  Type "show warranty" for details.
This GDB was configured as "i386-suse-linux"...
/home/jens/Lab/fsc2/28805: No such file or directory.
Attaching to program: /home/jens/Lab/fsc2/src/fsc2, Pid 28805
Reading symbols from /usr/X11R6/lib/libforms.so.1...done.
Loaded symbols for /usr/X11R6/lib/libforms.so.1
Reading symbols from /usr/X11R6/lib/libX11.so.6...done.
Loaded symbols for /usr/X11R6/lib/libX11.so.6
Reading symbols from /lib/libm.so.6...done.
Loaded symbols for /lib/libm.so.6
Reading symbols from /lib/libdl.so.2...done.
Loaded symbols for /lib/libdl.so.2
Reading symbols from /usr/local/lib/libgpib.so...done.
Loaded symbols for /usr/local/lib/libgpib.so
Reading symbols from /lib/libc.so.6...done.
Loaded symbols for /lib/libc.so.6
Reading symbols from /usr/X11R6/lib/libXext.so.6...done.
Loaded symbols for /usr/X11R6/lib/libXext.so.6
Reading symbols from /usr/X11R6/lib/libXpm.so.4...done.
Loaded symbols for /usr/X11R6/lib/libXpm.so.4
Reading symbols from /lib/ld-linux.so.2...done.
Loaded symbols for /lib/ld-linux.so.2
Reading symbols from /lib/libnss_compat.so.2...done.
Loaded symbols for /lib/libnss_compat.so.2
Reading symbols from /lib/libnsl.so.1...done.
Loaded symbols for /lib/libnsl.so.1
Reading symbols from /usr/lib/gconv/ISO8859-1.so...done.
Loaded symbols for /usr/lib/gconv/ISO8859-1.so
Reading symbols from /usr/local/lib/fsc2/fsc2_rsc_lr.so...done.
Loaded symbols for /usr/local/lib/fsc2/fsc2_rsc_lr.so
Reading symbols from /usr/local/lib/fsc2/User_Functions.so...done.
Loaded symbols for /usr/local/lib/fsc2/User_Functions.so
0x40698951 in __libc_nanosleep () from /lib/libc.so.6
(gdb)
@end example
@noindent
Now the child process will be waiting at the very start of its code
in the function @code{run_child()} in the file @file{run.c}.

Please note that because @code{fsc2} is normally running as a setuid-ed
process you must not try to debug the already installed and setuid-ed
version (that's not allowed for security reason) but only a version for
which belongs to you and for which you have unlimited execution
permissions. This might require that you temporarily change the
permissions to allow access by all users for all device files (for the
GPIB board, the serial ports and, possibly, cards installed in the
computer and used by @code{fsc2}) for devices that are controlled by the
@code{EDL} script you use during debugging. Don't forget to reset the
permissions when you're done.


This point out of the way I'll start a tour de force through the
sources. When @code{fsc2} is invoked it starts at the code in
@code{main()} in the file @file{fsc2.c}. After setting up lots of global
variables and checking the command line options it tries to connect to a
kind of daemon process or start it if it's not already running.  This
daemon is taking care of situation where @code{fsc2} is running in
non-exclusive mode, i.e.@: more than instance of @code{fsc2} is to
be run at the same time, and it will tell new instances about what they
are allowed to do and what not to avoid more than one instance trying to
access the same devices at the same time.


When this hurdle has been taken the initialization of the graphics is
done. All the code for doing so is in the file @file{xinit.c}. You will
have to read a bit about the @code{Xforms} library to understand what's
going on there. Mostly it's loading a shared library for creating the
forms used by the program (there are two shared libraries,
@file{fsc2_rsc_lr.so} and @file{fsc2_rsc_hr.so}, which on is loaded
depends on the screen resolution and the comand line option
@code{-size}), evaluating the settings in the @file{.Xdefaults} and
@file{.Xresources} files, again setting up lots of global variables and
doing further checks on the command line arguments.


When this part was successful some further checks of the remaining
command line options are done and, if specified on the command line,
an @code{EDL} script is loaded. Now we're already near to start the
main loop of the program. But before this loop is entered another new
process is spawned that opens a socket (of type @code{AF_UNIX}) to
listen on incoming connections from external programs that want to send
@code{EDL} scripts to @code{fsc2} for execution. The code for spawning
this child process and the code for the child process itself is to be
found in the @file{conn.c}.


After this stage the main loop of the program is entered. It consists of
just these two lines:
@example
while ( fl_do_forms( ) != GUI.main_form->quit )
    /* empty */ ;
@end example
Everything else is hidden behind these two lines. What they do is to
wait for new events until the @code{Quit} button gets pressed. Possible
events are clicking on the buttons in the different form, but they don't
need to be mentioned in this loop because all buttons trigger callback
functions when clicked on. The remaining stuff in the @code{main()}
function is just cleaning up when the program quits and a few things for
dealing with certain circumstances.


When you want to understand what's really going on you will have to
start with figuring out what happens in the callback functions for the
different buttons. The simplest way to find out which callback functions
are associated with which functions is probably to use the
@code{fdesign} program coming with the @code{Xforms} library and
starting it on one of the files @file{fsc2_rsc_lr.fd} or
@code{fsc2_rsc_hr.fd}. From within it you can display all of the forms
used by the program and find out the names of the callback functions
associated with each element of the forms.


The callback functions for the buttons of the main form are mostly in
@file{fsc2.c}. I will restrict myself to the most important ones: The
@code{Load} button invokes the function @code{load_file()}, which is
quite forward -- it asks the user to select a new file, checks if it
exists and can be read and, if this tests succeed, loads the file and
displays it in the main browser.


Once a file has been read in the @code{Test} button gets activated.
When it gets clicked on the function @code{test_file()} gets invoked and
that's were things get interesting. As you will find over and over again
in the program is starts with lots of testing and adjustments of the
buttons of the main form. (If you should worry about lines like
@example
notify_conn( BUSY_SIGNAL );
@end example
@noindent
@example
notify_conn( UNBUSY_SIGNAL );
@end example
@noindent
are about: these tell the child process listening for external
connections that @code{fsc2} is at the moment too busy accepting a new
@code{EDL} script and then that it's again prepared to load sucg a
script.)

The real fun starts at the line
@example
state = scan_main( EDL.in_file, in_file_fp );
@end example
@noindent
which calls the central subroutine to parse and test the @code{EDL}
script. A good deal of the following is going to be concerned what's
happening here.


The function @code{scan_main()} is located in the file
@file{split_lexer.l}. This obviously isn't a normall @code{C} file but a
file from which the @code{flex} utility creates a @code{C}
file. @code{flex} is a tool that generates programs that perfom
pattern-matching on input text. That means that a program created by
@code{flex} will dissect an input text into the tokens according to the
rules of how these tokens are supposed to look like defined in the
@code{.l} file. And that's exactly what needs to be done with an
@code{EDL} script before it can later be digested by @code{fsc2} (with
the help of another tool, @code{bison}).


That's it for the moment, the sequel is coming soon, please stay tuned ;-)
